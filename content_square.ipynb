{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188b2fb-3068-44c6-aed4-4c3bf897018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import important libaraies\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import csv\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "# your custom options...\n",
    "options.page_load_strategy = 'eager'\n",
    "driver = webdriver.Chrome(\n",
    "    service=service,\n",
    "    options=options\n",
    ")\n",
    "\n",
    "driver.maximize_window()\n",
    "driver.get('https://partners.contentsquare.com/technology-partners')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb331fd3-f70c-4ff5-a355-7cdbb17a3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_links = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, '//label[@class=\"relative flex items-start py-1\"]/div[@class=\"ml-3\"]/div')))\n",
    "a_links = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"grid grid-cols-1 gap-5 sm:grid-cols-2 lg:grid-cols-3\"]/a')))\n",
    "\n",
    "data=[]\n",
    "for _ in range(len(main_links)):\n",
    "    time.sleep(2)\n",
    "    main_links[_].click()\n",
    "    time.sleep(2)\n",
    "    current_category = main_links[_].text\n",
    "    print(f\"Current Category: {current_category}\")\n",
    "    a_links = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"grid grid-cols-1 gap-5 sm:grid-cols-2 lg:grid-cols-3\"]/a')))\n",
    "    for idx, link in enumerate(a_links, start=1):\n",
    "        try:\n",
    "            time.sleep(2)\n",
    "            # Open the link in a new tab\n",
    "            driver.execute_script(\"window.open(arguments[0], '_blank');\", link.get_attribute('href'))\n",
    "\n",
    "            # Switch to the new tab\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            list_page_url = driver.current_url\n",
    "            time.sleep(3)\n",
    "\n",
    "            # Extract name\n",
    "            scraping_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            rank = f\"{current_category}-{idx}\"\n",
    "            print(rank)\n",
    "\n",
    "            # Print the scraping date\n",
    "            print(\"Scraping Date:\", scraping_date)\n",
    "            try:\n",
    "                name = driver.find_element(By.XPATH, '//h1[@class=\"typography-h2 notranslate break-words\"]').text\n",
    "                print(name)\n",
    "            except NoSuchElementException:\n",
    "                name = ''\n",
    "\n",
    "            # Extract Icon url\n",
    "            try:\n",
    "                icon = driver.find_element(By.XPATH, '//div[@class=\"h-full w-full p-3\"]/img')\n",
    "                icon_url = icon.get_attribute('src')\n",
    "                print(icon_url)\n",
    "            except NoSuchElementException:\n",
    "                icon_url = ''\n",
    "\n",
    "            # extract description\n",
    "            try:\n",
    "                short_desc = driver.find_element(By.XPATH, '//div[@class=\"min-w-0 grow\"]/p[@class=\"mt-4\"]').text\n",
    "                print(short_desc)\n",
    "            except NoSuchElementException:\n",
    "                short_desc = ''\n",
    "\n",
    "            try:\n",
    "                category= driver.find_element(By.XPATH,'//div[@class=\"px-5 py-0 last:pb-5 inline-flex w-full flex-col space-y-5 first:pt-5\"]/section/div[@class=\"mt-1\"]').text\n",
    "            except NoSuchElementException:\n",
    "                category = ''\n",
    "    \n",
    "            try:\n",
    "                video = driver.find_element(By.XPATH,'//div[@class=\"absolute left-0 top-0 inline-flex h-full w-full items-center justify-center\"]/iframe')\n",
    "                video_url = video.get_attribute('src')\n",
    "            except NoSuchElementException:\n",
    "                video_url = ''\n",
    "    \n",
    "            try:\n",
    "                web=  driver.find_element(By.XPATH,'//div[@class=\"mt-2 flex h-10 items-center gap-x-4\"]/a')\n",
    "                web_url = web.get_attribute('href')\n",
    "            except NoSuchElementException:\n",
    "                web_url = ''\n",
    "    \n",
    "            try:\n",
    "                contact=  driver.find_element(By.XPATH,'//div[@class=\"mt-8\"]/a')\n",
    "                contact_url = contact.get_attribute('href')\n",
    "            except NoSuchElementException:\n",
    "                contact_url = ''\n",
    "    \n",
    "            try:\n",
    "                resources_elements = driver.find_elements(By.XPATH, '//ul[@class=\"mt-2 flex flex-col items-start space-y-2\"]/li/a')\n",
    "                resources_urls = []\n",
    "            \n",
    "                # Iterate through each resource element\n",
    "                for resource in resources_elements:\n",
    "                    # Get the URL of each resource\n",
    "                    resource_url = resource.get_attribute('href')\n",
    "            \n",
    "                    # Add the URL to the list\n",
    "                    resources_urls.append(resource_url)\n",
    "            \n",
    "                    # Now, resources_urls contains all the URLs of the resources\n",
    "            \n",
    "                # Convert the list of URLs to a string separated by commas\n",
    "                resources_urls_str = ', '.join(resources_urls)\n",
    "                print(resources_urls_str)\n",
    "            \n",
    "            except NoSuchElementException:\n",
    "                resources_urls_str = ''\n",
    "                print(resources_urls_str)\n",
    "    \n",
    "            try:\n",
    "                use_cases= driver.find_element(By.XPATH,'//section[@class=\"mt-8 first:mt-0\"]/ul').text\n",
    "            except NoSuchElementException:\n",
    "                use_cases = ''\n",
    "    \n",
    "            try:\n",
    "                integration= driver.find_element(By.XPATH,'(//section/div[@class=\"mt-1\"])[position()=2]').text\n",
    "            except NoSuchElementException:\n",
    "                integration = ''\n",
    "    \n",
    "            try:\n",
    "                pic1 = driver.find_element(By.XPATH,'//div[@class=\"h-full w-full overflow-hidden\"]/img')\n",
    "                pic1_url = pic1.get_attribute('src')\n",
    "            except NoSuchElementException:\n",
    "                pic1_url = ''\n",
    "    \n",
    "            try:\n",
    "                pic2 = driver.find_element(By.XPATH,'(//div[@class=\"h-full w-full overflow-hidden\"]/img)[position()=2]')\n",
    "                pic2_url = pic2.get_attribute('src')\n",
    "            except NoSuchElementException:\n",
    "                pic2_url = ''\n",
    "    \n",
    "            try:\n",
    "                pic3 = driver.find_element(By.XPATH,'(//div[@class=\"h-full w-full overflow-hidden\"]/img)[position()=3]')\n",
    "                pic3_url = pic3.get_attribute('src')\n",
    "            except NoSuchElementException:\n",
    "                pic3_url = ''\n",
    "    \n",
    "            try:\n",
    "                pic4 = driver.find_element(By.XPATH,'(//div[@class=\"h-full w-full overflow-hidden\"]/img)[position()=4]')\n",
    "                pic4_url = pic4.get_attribute('src')\n",
    "            except NoSuchElementException:\n",
    "                pic4_url = ''\n",
    "    \n",
    "            \n",
    "            data.append([list_page_url, name, icon_url,short_desc,category, video_url, web_url, contact_url,  resources_urls_str, use_cases,integration,pic1_url ,pic2_url, pic3_url, pic4_url, rank, scraping_date])\n",
    "           \n",
    "            # Go back to the previous page (list of articles)\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            a_links = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"grid grid-cols-1 gap-5 sm:grid-cols-2 lg:grid-cols-3\"]/a')))\n",
    "        except Exception as e:\n",
    "            # Handle exceptions here (e.g., skip non-clickable links)\n",
    "            print(f\"Skipping link due to exception: {str(e)}\")\n",
    "            continue\n",
    "            a_links = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"grid grid-cols-1 gap-5 sm:grid-cols-2 lg:grid-cols-3\"]/a')))\n",
    "    time.sleep(2)\n",
    "    main_links[_].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc194c-4578-4a22-a8a9-c46588e3e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transfer into excel file according to fields\n",
    "df = pd.DataFrame(data, columns=['Listing URL', 'Name', 'Icon URL', 'Short Description' ,'Categories','Video URL1' ,'Visit Website URL','Contact Tech Partner URL','Resources URL','Use cases','Integration','Picture URL1','Picture URL2','Picture URL3','Picture URL4','ListingRank' ,'ListingScrapeDate'])\n",
    "df.to_excel('contentsq.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
